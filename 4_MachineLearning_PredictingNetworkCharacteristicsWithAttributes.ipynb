{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766e9bee-8864-4735-a7d0-e9a051122025",
   "metadata": {},
   "source": [
    "# Project: Trying to Predict Network Characteristics Using Attribute Data + Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d54c712-4d13-4e1d-976e-de8691ebe55b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Network data is generally harder to collect than attribute data, so naturally there may be an attempt to predict networking characteristics with machine learning models trained on attribute data.\n",
    "\n",
    "The objective of this project is to demonstrate that networking characteristics among entities are fundamentally distinct from entity attributes and cannot be effectively predicted using attribute data alone, regardless of the machine learning models employed.\n",
    "\n",
    "This project will utilize 'G03B_attribute_centrality_position.csv' and 'G03F_attribute_centrality_position.csv' as examples. These datasets contain both entity attributes and networking characteristics (centrality indicators and network position). We will employ various supervised machine learning models to predict centrality indicators using entity attributes as the input data.\n",
    "\n",
    "Our goal is to maximize the predictive power of these models and illustrate the substantial disparity between attributes and networking characteristics, which cannot be bridged by conventional machine learning models. Ultimately, this will underscore the importance of acquiring network data and adopting graph-based approaches to address relationship structural problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d209f6f4-9e83-42a1-a72a-43f1b379b0ee",
   "metadata": {},
   "source": [
    "## Contents\n",
    "* Preparing Data: cleaning, one-hot encoding, scaling, polynomial features, feature selection, feature extraction\n",
    "* Regression: Predicting centrality with attributes\n",
    "* Regression: Predicting centrality with attributes + other centralities\n",
    "* Classification: Predicting network position with attributes\n",
    "* Classification: Predicting network position with attributes + centralities\n",
    "* Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d4a16d-b5b8-4bf8-972f-e44d351c0c66",
   "metadata": {},
   "source": [
    "##  Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93a6a31-a74b-4a88-9f5a-7bdfb7074b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bd1593d-63eb-4226-a4a9-792efca2c531",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = pd.read_csv(r\"C:\\Users\\user\\Documents\\G03F_attribute_centrality_position.csv\", index_col = 0)\n",
    "B = pd.read_csv(r\"C:\\Users\\user\\Documents\\G03B_attribute_centrality_position.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fe1048-7eaa-48d3-8f67-9e39bea2c96f",
   "metadata": {},
   "source": [
    "### cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47989909-23d2-4e7b-928a-09f7e66f5d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add IPC column\n",
    "F['IPC'] = 'G03F'\n",
    "B['IPC'] = 'G03B'\n",
    "\n",
    "# merge two df\n",
    "df = pd.concat([B,F], axis = 0)\n",
    "\n",
    "# fill all missing value with 0\n",
    "df = df.fillna(0)\n",
    "\n",
    "# for position_class column, change 0 to 'not included'\n",
    "df.loc[df['position_class'] == 0,'position_class'] = 'not included'\n",
    "# combine 'isolate nodes' and 'isolate community' to new class 'isolates'\n",
    "df.loc[df['position_class'] == 'isolate node','position_class'] = 'isolates'\n",
    "df.loc[df['position_class'] == 'isolate community','position_class'] = 'isolates'\n",
    "\n",
    "# Transform the country column\n",
    "allowed_countries = {'US', 'JP', 'TW', 'KR', 'CN'}\n",
    "df['Country'] = df['國家'].apply(lambda x: x if x in allowed_countries else 'Others')\n",
    "#df['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd835cde-09e9-464b-9c9d-55f81ae9208c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 551 entries, 0 to 185\n",
      "Data columns (total 21 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   專利權人            551 non-null    object \n",
      " 1   專利件數            551 non-null    int64  \n",
      " 2   他人引證次數          551 non-null    int64  \n",
      " 3   自我引證次數          551 non-null    int64  \n",
      " 4   發明人數            551 non-null    int64  \n",
      " 5   平均專利年齡          551 non-null    int64  \n",
      " 6   活動年期            551 non-null    int64  \n",
      " 7   相對研發能力          551 non-null    float64\n",
      " 8   國家              551 non-null    object \n",
      " 9   時期              551 non-null    object \n",
      " 10  indegree        551 non-null    float64\n",
      " 11  closeness       551 non-null    float64\n",
      " 12  betweenness     551 non-null    float64\n",
      " 13  harmonic        551 non-null    float64\n",
      " 14  eigenvector     551 non-null    float64\n",
      " 15  katz            551 non-null    float64\n",
      " 16  pagerank        551 non-null    float64\n",
      " 17  laplacian       551 non-null    float64\n",
      " 18  position_class  551 non-null    object \n",
      " 19  IPC             551 non-null    object \n",
      " 20  Country         551 non-null    object \n",
      "dtypes: float64(9), int64(6), object(6)\n",
      "memory usage: 94.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75cd1975-3b63-4bc0-b904-20b0625986e5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>專利權人</th>\n",
       "      <td>551</td>\n",
       "      <td>130</td>\n",
       "      <td>ASML NETHERLANDS</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>專利件數</th>\n",
       "      <td>551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.495463</td>\n",
       "      <td>72.043847</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>638.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>他人引證次數</th>\n",
       "      <td>551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.580762</td>\n",
       "      <td>11.2198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>自我引證次數</th>\n",
       "      <td>551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.537205</td>\n",
       "      <td>30.158279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>發明人數</th>\n",
       "      <td>551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.526316</td>\n",
       "      <td>95.860423</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>平均專利年齡</th>\n",
       "      <td>551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.435572</td>\n",
       "      <td>4.793075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>活動年期</th>\n",
       "      <td>551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.591652</td>\n",
       "      <td>1.331521</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>相對研發能力</th>\n",
       "      <td>551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102976</td>\n",
       "      <td>0.183335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>國家</th>\n",
       "      <td>551</td>\n",
       "      <td>15</td>\n",
       "      <td>US</td>\n",
       "      <td>211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>時期</th>\n",
       "      <td>551</td>\n",
       "      <td>4</td>\n",
       "      <td>2009_2013</td>\n",
       "      <td>149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indegree</th>\n",
       "      <td>551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030162</td>\n",
       "      <td>0.051717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.348837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>closeness</th>\n",
       "      <td>551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083911</td>\n",
       "      <td>0.109295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166957</td>\n",
       "      <td>0.392386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>betweenness</th>\n",
       "      <td>551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006293</td>\n",
       "      <td>0.019319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.189544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harmonic</th>\n",
       "      <td>551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.824423</td>\n",
       "      <td>8.732782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.833333</td>\n",
       "      <td>40.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eigenvector</th>\n",
       "      <td>551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.056698</td>\n",
       "      <td>0.106419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064254</td>\n",
       "      <td>0.7071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>katz</th>\n",
       "      <td>551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.091404</td>\n",
       "      <td>0.078585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090898</td>\n",
       "      <td>0.146678</td>\n",
       "      <td>0.329401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pagerank</th>\n",
       "      <td>551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014519</td>\n",
       "      <td>0.024772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007429</td>\n",
       "      <td>0.014465</td>\n",
       "      <td>0.197347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laplacian</th>\n",
       "      <td>551.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036121</td>\n",
       "      <td>0.032997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033028</td>\n",
       "      <td>0.055016</td>\n",
       "      <td>0.226524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>position_class</th>\n",
       "      <td>551</td>\n",
       "      <td>5</td>\n",
       "      <td>largest community</td>\n",
       "      <td>190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IPC</th>\n",
       "      <td>551</td>\n",
       "      <td>2</td>\n",
       "      <td>G03B</td>\n",
       "      <td>365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <td>551</td>\n",
       "      <td>6</td>\n",
       "      <td>US</td>\n",
       "      <td>211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count unique                top freq       mean        std  \\\n",
       "專利權人              551    130   ASML NETHERLANDS    8        NaN        NaN   \n",
       "專利件數            551.0    NaN                NaN  NaN  36.495463  72.043847   \n",
       "他人引證次數          551.0    NaN                NaN  NaN   4.580762    11.2198   \n",
       "自我引證次數          551.0    NaN                NaN  NaN   6.537205  30.158279   \n",
       "發明人數            551.0    NaN                NaN  NaN  50.526316  95.860423   \n",
       "平均專利年齡          551.0    NaN                NaN  NaN   9.435572   4.793075   \n",
       "活動年期            551.0    NaN                NaN  NaN   3.591652   1.331521   \n",
       "相對研發能力          551.0    NaN                NaN  NaN   0.102976   0.183335   \n",
       "國家                551     15                 US  211        NaN        NaN   \n",
       "時期                551      4          2009_2013  149        NaN        NaN   \n",
       "indegree        551.0    NaN                NaN  NaN   0.030162   0.051717   \n",
       "closeness       551.0    NaN                NaN  NaN   0.083911   0.109295   \n",
       "betweenness     551.0    NaN                NaN  NaN   0.006293   0.019319   \n",
       "harmonic        551.0    NaN                NaN  NaN   5.824423   8.732782   \n",
       "eigenvector     551.0    NaN                NaN  NaN   0.056698   0.106419   \n",
       "katz            551.0    NaN                NaN  NaN   0.091404   0.078585   \n",
       "pagerank        551.0    NaN                NaN  NaN   0.014519   0.024772   \n",
       "laplacian       551.0    NaN                NaN  NaN   0.036121   0.032997   \n",
       "position_class    551      5  largest community  190        NaN        NaN   \n",
       "IPC               551      2               G03B  365        NaN        NaN   \n",
       "Country           551      6                 US  211        NaN        NaN   \n",
       "\n",
       "                min   25%       50%       75%       max  \n",
       "專利權人            NaN   NaN       NaN       NaN       NaN  \n",
       "專利件數            1.0   5.0      14.0      29.0     638.0  \n",
       "他人引證次數          0.0   0.0       1.0       4.0     103.0  \n",
       "自我引證次數          0.0   0.0       0.0       3.0     543.0  \n",
       "發明人數            1.0   8.0      21.0      53.0    1211.0  \n",
       "平均專利年齡          1.0   6.0       9.0      13.0      18.0  \n",
       "活動年期            1.0   3.0       4.0       5.0       5.0  \n",
       "相對研發能力          0.0  0.01      0.04      0.11       1.0  \n",
       "國家              NaN   NaN       NaN       NaN       NaN  \n",
       "時期              NaN   NaN       NaN       NaN       NaN  \n",
       "indegree        0.0   0.0       0.0      0.04  0.348837  \n",
       "closeness       0.0   0.0       0.0  0.166957  0.392386  \n",
       "betweenness     0.0   0.0       0.0  0.000886  0.189544  \n",
       "harmonic        0.0   0.0       0.0  9.833333     40.75  \n",
       "eigenvector     0.0   0.0       0.0  0.064254    0.7071  \n",
       "katz            0.0   0.0  0.090898  0.146678  0.329401  \n",
       "pagerank        0.0   0.0  0.007429  0.014465  0.197347  \n",
       "laplacian       0.0   0.0  0.033028  0.055016  0.226524  \n",
       "position_class  NaN   NaN       NaN       NaN       NaN  \n",
       "IPC             NaN   NaN       NaN       NaN       NaN  \n",
       "Country         NaN   NaN       NaN       NaN       NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include = 'all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bbcaea4-a675-467c-ae10-6c4f5dd818d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['專利權人', '專利件數', '他人引證次數', '自我引證次數', '發明人數', '平均專利年齡', '活動年期', '相對研發能力',\n",
       "       '國家', '時期', 'indegree', 'closeness', 'betweenness', 'harmonic',\n",
       "       'eigenvector', 'katz', 'pagerank', 'laplacian', 'position_class', 'IPC',\n",
       "       'Country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a240d97-8159-48da-be95-a1c687c12b37",
   "metadata": {},
   "source": [
    "### dataset for each section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f307a7c8-236a-484f-96d7-bcc7806e2efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns for section 2 'predicting centrality with attributes'\n",
    "df2 = df.loc[:,['專利件數', '他人引證次數', '自我引證次數', '發明人數', '平均專利年齡', '活動年期', '時期', 'IPC', 'Country', \n",
    "                'pagerank']] # to be simple, we only choose pagerank as target centrality\n",
    "\n",
    "# select columns for section 3 'predicting centrality with attributes and other centralities'\n",
    "df3 = df.loc[:,['專利件數', '他人引證次數', '自我引證次數', '發明人數', '平均專利年齡', '活動年期', '時期', 'IPC', 'Country', \n",
    "                'indegree', 'closeness', 'betweenness', 'harmonic', 'eigenvector', 'katz', 'laplacian', \n",
    "                'pagerank']] # pagerank centrality is target\n",
    "\n",
    "# select columns for section 4 'predicting network position with attributes'\n",
    "df4 = df.loc[:,['專利件數', '他人引證次數', '自我引證次數', '發明人數', '平均專利年齡', '活動年期', '時期', 'IPC', 'Country', \n",
    "                'position_class']] # position_class is target\n",
    "\n",
    "# select columns for section 5 'predicting network position with attributes and centralities'\n",
    "df5 = df.loc[:,['專利件數', '他人引證次數', '自我引證次數', '發明人數', '平均專利年齡', '活動年期', '時期', 'IPC', 'Country', \n",
    "                'indegree', 'closeness', 'betweenness', 'harmonic', 'eigenvector', 'katz', 'pagerank', 'laplacian', \n",
    "                'position_class']] # position_class is target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc1100f-00f0-46af-ad06-42ba21685ddf",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17152985-378d-4a17-a8e7-78e18c67e9f5",
   "metadata": {},
   "source": [
    "1. define features and target\n",
    "2. train test split\n",
    "3. numerical features pipeline: scaling, polynomial feature generation, intitial feature selection\n",
    "4. categorical features pipeline: one-hot encoding\n",
    "5. all features pipeline: feature selection and feauture extraction (PCA)\n",
    "6. fit_transform x_train with pipeline\n",
    "7. transform x_test with the same pipeline\n",
    "8. return X_train_processed, X_test_processed, y_train, y_test\n",
    "\n",
    "The dataset we are using is small, only 551 data points. The following model trainings will control number of features to be 20 in each section, so that evaluation metrics could be compared between each section (same train, val, test dataset size; same number of features and preprocessing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a90da94b-9af8-4eb3-bd41-f4ae40680374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder, LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_regression, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fbb0ff4-88a2-4318-a5fb-c7607045b423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define preprocessing function for regression task\n",
    "def preprocessing_20features_traintestsplit(df):\n",
    "    # Define features and target\n",
    "    X = df.drop(df.columns[-1], axis=1)\n",
    "    y = df.iloc[:,-1]\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, random_state=42)\n",
    "\n",
    "    # Identify numerical and categorical columns\n",
    "    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    # Preprocessing for numerical data\n",
    "    numerical_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Scaling\n",
    "        ('polynomial', PolynomialFeatures(degree=2, include_bias=False)),  # Polynomial features\n",
    "        ('variance_threshold', VarianceThreshold(threshold=0.1)),  # Initial feature selection\n",
    "    ])\n",
    "\n",
    "    # Preprocessing for categorical data\n",
    "    categorical_pipeline = Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')),  # One-hot encoding\n",
    "    ])\n",
    "\n",
    "    # Combine preprocessing steps\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features),\n",
    "    ])\n",
    "\n",
    "    # Full pipeline including feature selection and extraction\n",
    "    full_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('select_k_best', SelectKBest(score_func=f_regression, k=30)),  # Feature selection on transformed features\n",
    "        ('pca', PCA(n_components=20)),  # Feature extraction\n",
    "    ])\n",
    "\n",
    "    # Fit and transform the training data\n",
    "    X_train_processed = full_pipeline.fit_transform(X_train, y_train)\n",
    "    X_test_processed = full_pipeline.transform(X_test)\n",
    "\n",
    "    # Output the processed features for verification\n",
    "    print(\"Processed training features shape:\", X_train_processed.shape)\n",
    "    print(\"Processed testing features shape:\", X_test_processed.shape)\n",
    "\n",
    "    return X_train_processed, X_test_processed, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68a1972d-d440-41ab-923b-5d06ba7700d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define preprocessing function for classification task\n",
    "def preprocessing_20features_multiclasstarget_traintestsplit(df):\n",
    "    # Define features and target\n",
    "    X = df.drop(df.columns[-1], axis=1)\n",
    "    y = df.iloc[:,-1]\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle = True, random_state=42)\n",
    "\n",
    "    # Identify numerical and categorical columns\n",
    "    numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    # Preprocessing for numerical data\n",
    "    numerical_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),  # Scaling\n",
    "        ('polynomial', PolynomialFeatures(degree=2, include_bias=False)),  # Polynomial features\n",
    "        ('variance_threshold', VarianceThreshold(threshold=0.1)),  # Initial feature selection\n",
    "    ])\n",
    "\n",
    "    # Preprocessing for categorical data\n",
    "    categorical_pipeline = Pipeline([\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore')),  # One-hot encoding\n",
    "    ])\n",
    "\n",
    "    # Combine preprocessing steps\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features),\n",
    "    ])\n",
    "\n",
    "    # Full pipeline including feature selection and extraction\n",
    "    full_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('select_k_best', SelectKBest(score_func=f_classif, k=30)),  # Feature selection on transformed features\n",
    "        ('pca', PCA(n_components=20)),  # Feature extraction\n",
    "    ])\n",
    "\n",
    "    # Fit and transform the training data\n",
    "    X_train_processed = full_pipeline.fit_transform(X_train, y_train)\n",
    "    X_test_processed = full_pipeline.transform(X_test)\n",
    "\n",
    "    # Label encoding the target variable\n",
    "    le = LabelEncoder()\n",
    "    y_train_encoded = le.fit_transform(y_train)\n",
    "    y_test_encoded = le.transform(y_test)\n",
    "    \n",
    "    # Output the processed features for verification\n",
    "    print(\"Processed training features shape:\", X_train_processed.shape)\n",
    "    print(\"Processed testing features shape:\", X_test_processed.shape)\n",
    "    print(\"Encoded training target shape:\", y_train_encoded.shape)\n",
    "    print(\"Encoded testing target shape:\", y_test_encoded.shape)\n",
    "\n",
    "    return X_train_processed, X_test_processed, y_train_encoded, y_test_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3ec24f-f31b-48da-9a9c-2b0ce2e4ba5a",
   "metadata": {},
   "source": [
    "## Regression: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685082cc-efdc-49c6-b229-4a01dfd83f8a",
   "metadata": {},
   "source": [
    "We will use pagerank centrality as target:\n",
    "\n",
    "|Centrality|Description|\n",
    "|---|---|\n",
    "|Indegree|Indegree centrality of a node is the number of neighbors that had chosen this node. It is the simplest centrality indicator of a node in a network.|\n",
    "|Eigenvector|Eigenvector centrality computes the centrality for a node by adding the centrality of its neighbors. It reflects the importance of node i not just by counting how many neighbors does it has, but also take i's neighbors' importance into account. It could be seen as a more sophisticated and improved centrality indicator compared with indegree centrality.|\n",
    "|Pagerank|Originally, it was developed by Google to rank webpages. Pagerank could be seen as a further improvement based on eigenvector centrality. Like eigenvector centrality,  Pagerank also consider a node's importance based on it's neighbors, but, unlike eigenvector centrality, it further considers each neighbors' number of out degree to weight the contribution of each neighbor's importance to the focus node's importance.|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58a046f4-3411-46bb-8e58-d15f3c6bc77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95393e1b-e67b-46d4-9e96-2332035b02ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompareML_Regression(df):\n",
    "    # train test split\n",
    "    X_train, X_test, y_train, y_test = preprocessing_20features_traintestsplit(df)\n",
    "\n",
    "    # models and hyperparameters \n",
    "    models = {\n",
    "        'KNN': (KNeighborsRegressor(), {'n_neighbors': [2,4,8,16,20,24]}),\n",
    "        'DecisionTree': (DecisionTreeRegressor(), {'max_depth': [2, 3, 5, 7, 9, 11], 'min_samples_leaf':[1,2,4,6,8]}),\n",
    "        'RandomForest': (RandomForestRegressor(), {'n_estimators':[10, 20, 40, 80, 100], 'max_depth':[2, 3, 5, 7, 9, 11],\n",
    "                                                 'min_samples_leaf':[1,2,4,6,8]}),\n",
    "        'GradientBoosting':(GradientBoostingRegressor(), {'learning_rate':[0.001, 0.01, 0.1], \n",
    "                                                          'n_estimators':[10, 20, 40, 80, 100]}),\n",
    "        'Ridge': (Ridge(), {'alpha': [0, 0.1, 1, 10, 100, 300, 500, 700]}),\n",
    "        'SVM': (SVR(), {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100], 'gamma':['scale', 'auto'], \n",
    "                        'kernel': ['linear', 'poly', 'rbf']})\n",
    "    }\n",
    "\n",
    "    # dictionary to store results\n",
    "    results = {'Model': [], 'Best Params': [],'Best Score':[], 'MSE': [], 'R2': []}\n",
    "\n",
    "    # perform GridSearchCV for each model\n",
    "    for model_name, (model, param_grid) in models.items():\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=cv, scoring='r2', n_jobs = -1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_score = grid_search.best_score_\n",
    "        best_params = grid_search.best_params_\n",
    "    \n",
    "        # Evaluate the best model on the test set\n",
    "        y_pred = best_model.predict(X_test)\n",
    "    \n",
    "        # Calculate evaluation metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "        # Store the results\n",
    "        results['Model'].append(model_name)\n",
    "        results['Best Params'].append(best_params)\n",
    "        results['Best Score'].append(best_score)\n",
    "        results['MSE'].append(mse)\n",
    "        results['R2'].append(r2)\n",
    "\n",
    "    # store results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffc0572-fda4-433a-9668-ac4460b96d1d",
   "metadata": {},
   "source": [
    "### Predicting centrality with attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90af40c8-bd70-4f65-8e26-a0f738ee2336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed training features shape: (440, 20)\n",
      "Processed testing features shape: (111, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 16}</td>\n",
       "      <td>0.403070</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.355940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>{'max_depth': 3, 'min_samples_leaf': 4}</td>\n",
       "      <td>0.232572</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.201973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 2, 'n_est...</td>\n",
       "      <td>0.435975</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.369874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 40}</td>\n",
       "      <td>0.269770</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.492978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>{'alpha': 500}</td>\n",
       "      <td>0.275974</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.293966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 0.0001, 'gamma': 'scale', 'kernel': 'lin...</td>\n",
       "      <td>-13.416575</td>\n",
       "      <td>0.007858</td>\n",
       "      <td>-11.339013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model                                        Best Params  \\\n",
       "0               KNN                                {'n_neighbors': 16}   \n",
       "1      DecisionTree            {'max_depth': 3, 'min_samples_leaf': 4}   \n",
       "2      RandomForest  {'max_depth': 7, 'min_samples_leaf': 2, 'n_est...   \n",
       "3  GradientBoosting         {'learning_rate': 0.1, 'n_estimators': 40}   \n",
       "4             Ridge                                     {'alpha': 500}   \n",
       "5               SVM  {'C': 0.0001, 'gamma': 'scale', 'kernel': 'lin...   \n",
       "\n",
       "   Best Score       MSE         R2  \n",
       "0    0.403070  0.000410   0.355940  \n",
       "1    0.232572  0.000508   0.201973  \n",
       "2    0.435975  0.000401   0.369874  \n",
       "3    0.269770  0.000323   0.492978  \n",
       "4    0.275974  0.000450   0.293966  \n",
       "5  -13.416575  0.007858 -11.339013  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CompareML_Regression(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e87d33-c883-4b6e-86cd-06a5e7ce4457",
   "metadata": {},
   "source": [
    "### Predicting centrality with attributes + other centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e4afa9d-a226-4ef9-8106-f287b6b5ee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed training features shape: (440, 20)\n",
      "Processed testing features shape: (111, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 4}</td>\n",
       "      <td>0.719631</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.814343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>{'max_depth': 7, 'min_samples_leaf': 2}</td>\n",
       "      <td>0.660801</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.728438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 5, 'min_samples_leaf': 2, 'n_est...</td>\n",
       "      <td>0.764072</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.861817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 80}</td>\n",
       "      <td>0.745397</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.834083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>{'alpha': 300}</td>\n",
       "      <td>0.643556</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.840702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 0.0001, 'gamma': 'scale', 'kernel': 'lin...</td>\n",
       "      <td>-13.416575</td>\n",
       "      <td>0.007858</td>\n",
       "      <td>-11.339013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model                                        Best Params  \\\n",
       "0               KNN                                 {'n_neighbors': 4}   \n",
       "1      DecisionTree            {'max_depth': 7, 'min_samples_leaf': 2}   \n",
       "2      RandomForest  {'max_depth': 5, 'min_samples_leaf': 2, 'n_est...   \n",
       "3  GradientBoosting         {'learning_rate': 0.1, 'n_estimators': 80}   \n",
       "4             Ridge                                     {'alpha': 300}   \n",
       "5               SVM  {'C': 0.0001, 'gamma': 'scale', 'kernel': 'lin...   \n",
       "\n",
       "   Best Score       MSE         R2  \n",
       "0    0.719631  0.000118   0.814343  \n",
       "1    0.660801  0.000173   0.728438  \n",
       "2    0.764072  0.000088   0.861817  \n",
       "3    0.745397  0.000106   0.834083  \n",
       "4    0.643556  0.000101   0.840702  \n",
       "5  -13.416575  0.007858 -11.339013  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CompareML_Regression(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c513b96-4e04-4f63-8817-4582cbfdeeb7",
   "metadata": {},
   "source": [
    "## Classification: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f18da-5227-4740-971f-b2bcf03e9799",
   "metadata": {},
   "source": [
    "Network position is a multi-class target variable:\n",
    "\n",
    "|class|description|\n",
    "|---|---|\n",
    "|largest community|nodes locates in the largest weakly connected component and also locates in the largest community defined by edge betweenness partition community detection|\n",
    "|other community|nodes locates in the largest weakly connected component but does not locate in the largest community defined by edge betweenness partition community detection|\n",
    "|isolates|nodes that does not locate in the largest weakly connected component, including isolated communities and isolated nodes|\n",
    "|not included|nodes that does not appear in the network|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33566df3-26c6-4eee-802d-0ac13e71074b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24af42d2-531c-4cbd-a8e3-5ffc932d6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompareML_Classification(df):\n",
    "    # train test split\n",
    "    X_train, X_test, y_train, y_test = preprocessing_20features_multiclasstarget_traintestsplit(df)\n",
    "\n",
    "    # models and hyperparameters \n",
    "    models = {\n",
    "        'KNN': (KNeighborsClassifier(), {'n_neighbors': [2,4,8,16,20,24]}),\n",
    "        'DecisionTree': (DecisionTreeClassifier(), {'max_depth': [2, 3, 5, 7, 9, 11], 'min_samples_leaf':[1,2,4,6,8]}),\n",
    "        'RandomForest': (RandomForestClassifier(), {'n_estimators':[10, 20, 40, 80, 100], 'max_depth':[2, 3, 5, 7, 9, 11],\n",
    "                                                 'min_samples_leaf':[1,2,4,6,8]}),\n",
    "        'GradientBoosting':(GradientBoostingClassifier(), {'learning_rate':[0.001, 0.01, 0.1], \n",
    "                                                          'n_estimators':[10, 20, 40, 80, 100]}),\n",
    "        'LogisticRegression': (LogisticRegression(), {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'max_iter':[1000]}),\n",
    "        'SVM': (SVC(), {'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100], 'gamma':['scale', 'auto'], \n",
    "                        'kernel': ['linear', 'poly', 'rbf']})\n",
    "    }\n",
    "\n",
    "    # dictionary to store results\n",
    "    results = {'Model': [], 'Best Params': [],'Best Score':[], 'Accuracy': [], 'F1 Score': []}\n",
    "\n",
    "    # perform GridSearchCV for each model\n",
    "    for model_name, (model, param_grid) in models.items():\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=cv, scoring='accuracy', n_jobs = -1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_score = grid_search.best_score_\n",
    "        best_params = grid_search.best_params_\n",
    "    \n",
    "        # Evaluate the best model on the test set\n",
    "        y_pred = best_model.predict(X_test)\n",
    "    \n",
    "        # Calculate evaluation metrics\n",
    "        all_classes = np.unique(y_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average = 'weighted', labels = all_classes)\n",
    "    \n",
    "        # Store the results\n",
    "        results['Model'].append(model_name)\n",
    "        results['Best Params'].append(best_params)\n",
    "        results['Best Score'].append(best_score)\n",
    "        results['Accuracy'].append(accuracy)\n",
    "        results['F1 Score'].append(f1)\n",
    "        \n",
    "\n",
    "    # store results to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18ca07d-0c98-4c03-8464-52b74501e5a7",
   "metadata": {},
   "source": [
    "### Predicting network position with attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf3d0b3b-b525-461e-89e0-7f046366462a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed training features shape: (440, 20)\n",
      "Processed testing features shape: (111, 20)\n",
      "Encoded training target shape: (440,)\n",
      "Encoded testing target shape: (111,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 20}</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.630631</td>\n",
       "      <td>0.619331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>{'max_depth': 11, 'min_samples_leaf': 4}</td>\n",
       "      <td>0.552273</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.513065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 4, 'n_est...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.614176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 40}</td>\n",
       "      <td>0.643182</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.665136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 100, 'max_iter': 1000}</td>\n",
       "      <td>0.638636</td>\n",
       "      <td>0.612613</td>\n",
       "      <td>0.598633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 100, 'gamma': 'scale', 'kernel': 'linear'}</td>\n",
       "      <td>0.647727</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.642731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model                                        Best Params  \\\n",
       "0                 KNN                                {'n_neighbors': 20}   \n",
       "1        DecisionTree           {'max_depth': 11, 'min_samples_leaf': 4}   \n",
       "2        RandomForest  {'max_depth': 9, 'min_samples_leaf': 4, 'n_est...   \n",
       "3    GradientBoosting         {'learning_rate': 0.1, 'n_estimators': 40}   \n",
       "4  LogisticRegression                       {'C': 100, 'max_iter': 1000}   \n",
       "5                 SVM   {'C': 100, 'gamma': 'scale', 'kernel': 'linear'}   \n",
       "\n",
       "   Best Score  Accuracy  F1 Score  \n",
       "0    0.575000  0.630631  0.619331  \n",
       "1    0.552273  0.513514  0.513065  \n",
       "2    0.636364  0.621622  0.614176  \n",
       "3    0.643182  0.666667  0.665136  \n",
       "4    0.638636  0.612613  0.598633  \n",
       "5    0.647727  0.666667  0.642731  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CompareML_Classification(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd66cc-ad9a-4a71-bb54-488e7e2061f5",
   "metadata": {},
   "source": [
    "### Predicting network position with attributes + centralities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba53c469-730a-4b7c-98c7-d2650c8a88f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed training features shape: (440, 20)\n",
      "Processed testing features shape: (111, 20)\n",
      "Encoded training target shape: (440,)\n",
      "Encoded testing target shape: (111,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>{'n_neighbors': 2}</td>\n",
       "      <td>0.770455</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.779203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 1}</td>\n",
       "      <td>0.752273</td>\n",
       "      <td>0.693694</td>\n",
       "      <td>0.694931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>{'max_depth': 9, 'min_samples_leaf': 1, 'n_est...</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.819824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 80}</td>\n",
       "      <td>0.759091</td>\n",
       "      <td>0.846847</td>\n",
       "      <td>0.843512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'C': 100, 'max_iter': 1000}</td>\n",
       "      <td>0.797727</td>\n",
       "      <td>0.846847</td>\n",
       "      <td>0.842407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>{'C': 100, 'gamma': 'scale', 'kernel': 'linear'}</td>\n",
       "      <td>0.790909</td>\n",
       "      <td>0.846847</td>\n",
       "      <td>0.844037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model                                        Best Params  \\\n",
       "0                 KNN                                 {'n_neighbors': 2}   \n",
       "1        DecisionTree            {'max_depth': 9, 'min_samples_leaf': 1}   \n",
       "2        RandomForest  {'max_depth': 9, 'min_samples_leaf': 1, 'n_est...   \n",
       "3    GradientBoosting         {'learning_rate': 0.1, 'n_estimators': 80}   \n",
       "4  LogisticRegression                       {'C': 100, 'max_iter': 1000}   \n",
       "5                 SVM   {'C': 100, 'gamma': 'scale', 'kernel': 'linear'}   \n",
       "\n",
       "   Best Score  Accuracy  F1 Score  \n",
       "0    0.770455  0.810811  0.779203  \n",
       "1    0.752273  0.693694  0.694931  \n",
       "2    0.784091  0.837838  0.819824  \n",
       "3    0.759091  0.846847  0.843512  \n",
       "4    0.797727  0.846847  0.842407  \n",
       "5    0.790909  0.846847  0.844037  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CompareML_Classification(df5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cc699b-e68d-41b0-b793-e8446d0cca7a",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8bb3b4-f34c-4d13-9c4f-afd5e0e3e19a",
   "metadata": {},
   "source": [
    "In the task of predicting PageRank centrality, machine learning models trained solely on entity attributes exhibit validation and test set R² values below 0.5. The highest test R² achieved is 0.49, obtained by a gradient boosting model. While more sophisticated models demonstrate better test set performance—Gradient Boosting (0.49) > Random Forest (0.36) > Decision Tree (0.2)—their overall performance remains unsatisfactory. However, incorporating additional network characteristics (such as other centralities) into the original dataset significantly improves the R² values on both validation and test sets, raising them to approximately 0.8-0.85.\n",
    "\n",
    "Some may argue that this substantial improvement in R² stems from centrality indicators like Katz and eigenvector centrality, which have similar measurements to PageRank centrality, and thus does not necessarily support the importance of network characteristics. This skepticism is addressed by the findings in the classification section.\n",
    "\n",
    "In the task of predicting network position, machine learning models trained solely on entity attributes achieve validation and test set accuracy between 0.5-0.65. The highest test accuracy and F1 score, both at 0.66, are achieved by a gradient boosting model. After adding centrality measures to the original dataset, both test set accuracy and F1 scores for all models significantly improve, exceeding 0.8. Given that network position classes are defined based on components and communities, which are distinct from node-level centrality indicators, the significant improvement in model performance cannot be attributed to similar measurement methods between features and target. Additionally, data preprocessing and model tuning procedures were consistently applied across sections, ensuring that these results are not influenced by machine learning techniques alone.\n",
    "\n",
    "The findings support the central argument of this project: Networking characteristics are distinct from attributes and cannot be predicted solely with attribute data, regardless of the machine learning model used. Addressing problems that are inherently network-based requires the adoption of network or graph-based data collection and analytics approaches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
